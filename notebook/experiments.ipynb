{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2791345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c8d4f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "301bc779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, the user is asking for the capital of France. Let me think... I remember from geography that France is a country in Europe. The capital... I believe it\\'s Paris. But wait, am I sure? Let me double-check. Sometimes countries have cities with similar names, but Paris is pretty unique. I think that\\'s right. Yeah, Paris is the capital and also a major city in France. It\\'s known as the City of Light, right? And it\\'s famous for the Eiffel Tower and the Louvre. I don\\'t think there\\'s any confusion with other cities. Yeah, I\\'m pretty confident the answer is Paris. No need to complicate it further.\\n</think>\\n\\nThe capital of France is **Paris**. Known as the \"City of Light,\" Paris is renowned for its cultural landmarks, such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral. It is a major global hub for art, fashion, and gastronomy. \\n\\nLet me know if you\\'d like additional details! ðŸ‡«ðŸ‡·' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 219, 'prompt_tokens': 15, 'total_tokens': 234, 'completion_time': 0.616167578, 'prompt_time': 0.000517014, 'queue_time': 0.050388716, 'total_time': 0.616684592}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_f17c2eb555', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--d488dac7-8f5d-4345-89bf-bab90dfea525-0' usage_metadata={'input_tokens': 15, 'output_tokens': 219, 'total_tokens': 234}\n"
     ]
    }
   ],
   "source": [
    "model=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "#model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "print(model.invoke(\"What is the capital of France?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53ae00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a7ef1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6955ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04257791489362717,\n",
       " -0.047810737043619156,\n",
       " -0.02702580951154232,\n",
       " -0.035097863525152206,\n",
       " 0.05324113741517067,\n",
       " 0.0018493696115911007,\n",
       " 0.004823467694222927,\n",
       " -0.022051338106393814,\n",
       " 0.0009697225177660584,\n",
       " 0.07324519753456116,\n",
       " -0.014812891371548176,\n",
       " 0.003644853364676237,\n",
       " -0.00034491211408749223,\n",
       " 0.028128888458013535,\n",
       " 0.025020018219947815,\n",
       " -0.04156218096613884,\n",
       " 0.005471833515912294,\n",
       " 0.02652869001030922,\n",
       " 0.043672770261764526,\n",
       " -0.014782802201807499,\n",
       " 0.013127882033586502,\n",
       " 0.007567551918327808,\n",
       " -0.03469207510352135,\n",
       " 0.023462051525712013,\n",
       " 0.020962651818990707,\n",
       " -0.05559537559747696,\n",
       " 0.00859882216900587,\n",
       " -0.04824773594737053,\n",
       " -0.012368501164019108,\n",
       " -0.001532181748189032,\n",
       " -0.07255345582962036,\n",
       " 0.04269229248166084,\n",
       " 0.00527808116748929,\n",
       " -0.015593086369335651,\n",
       " 0.02645784802734852,\n",
       " -0.0531519278883934,\n",
       " -0.0004922056687064469,\n",
       " 0.016876710578799248,\n",
       " -0.00814562477171421,\n",
       " 0.04225021228194237,\n",
       " -0.015036126598715782,\n",
       " -0.003916633781045675,\n",
       " -0.04687097668647766,\n",
       " 0.015219401568174362,\n",
       " -0.009408559650182724,\n",
       " -0.01825689896941185,\n",
       " -0.01993844285607338,\n",
       " 0.0748581662774086,\n",
       " 0.019254358485341072,\n",
       " -0.0052777305245399475,\n",
       " 0.012134595774114132,\n",
       " -0.010617725551128387,\n",
       " 0.054592013359069824,\n",
       " 0.020773116499185562,\n",
       " 0.013602628372609615,\n",
       " -0.06971295922994614,\n",
       " 0.008997276425361633,\n",
       " -0.014119189232587814,\n",
       " -0.0046128276735544205,\n",
       " 0.0210944302380085,\n",
       " 0.0329081267118454,\n",
       " -0.030065499246120453,\n",
       " 0.00447330716997385,\n",
       " 0.0407467782497406,\n",
       " 0.01971225067973137,\n",
       " -0.055106159299612045,\n",
       " 0.03556030988693237,\n",
       " 0.013304406777024269,\n",
       " 0.08534496277570724,\n",
       " 0.00158949033357203,\n",
       " -0.004593267105519772,\n",
       " -0.042083490639925,\n",
       " 0.0713706836104393,\n",
       " 0.005657872185111046,\n",
       " 0.030689362436532974,\n",
       " -0.0817095935344696,\n",
       " -0.02232016995549202,\n",
       " 0.06454379111528397,\n",
       " 0.01360271591693163,\n",
       " -0.04246792569756508,\n",
       " -0.00804409384727478,\n",
       " -0.05186443775892258,\n",
       " -0.07956809550523758,\n",
       " -0.02714453637599945,\n",
       " -0.05819103121757507,\n",
       " 0.014083041809499264,\n",
       " -0.05621412768959999,\n",
       " -0.018843192607164383,\n",
       " -0.05411393195390701,\n",
       " 0.04985203966498375,\n",
       " -0.025272108614444733,\n",
       " 0.006586411036550999,\n",
       " 0.07480309158563614,\n",
       " -0.040020957589149475,\n",
       " -0.028987407684326172,\n",
       " 0.06478418409824371,\n",
       " -0.014494857750833035,\n",
       " -0.011784432455897331,\n",
       " 0.07746846228837967,\n",
       " -0.003581888973712921,\n",
       " 0.01965465024113655,\n",
       " -0.021930739283561707,\n",
       " -0.07060352712869644,\n",
       " 0.05417868122458458,\n",
       " 0.03164941444993019,\n",
       " -0.00866173766553402,\n",
       " -0.01214554999023676,\n",
       " 0.058456458151340485,\n",
       " 0.006299072410911322,\n",
       " 0.06679613888263702,\n",
       " -0.0667213425040245,\n",
       " -0.04552998021245003,\n",
       " 0.031006908044219017,\n",
       " 0.06095348298549652,\n",
       " 0.01496248971670866,\n",
       " -0.05309277027845383,\n",
       " -0.03518706187605858,\n",
       " 0.017601503059267998,\n",
       " 0.03776673972606659,\n",
       " 0.024583736434578896,\n",
       " 0.035969726741313934,\n",
       " -0.018826857209205627,\n",
       " 0.044718313962221146,\n",
       " -0.045678626745939255,\n",
       " 0.034775298088788986,\n",
       " -0.01982470043003559,\n",
       " -0.04870112985372543,\n",
       " 0.032311610877513885,\n",
       " -0.011565012857317924,\n",
       " 0.021644998341798782,\n",
       " 0.015746233984827995,\n",
       " -0.04829183965921402,\n",
       " -0.014721618965268135,\n",
       " -0.002236217027530074,\n",
       " 0.014409353025257587,\n",
       " 0.030544603243470192,\n",
       " 0.061715949326753616,\n",
       " -0.018756143748760223,\n",
       " 0.04099138453602791,\n",
       " 0.006017507519572973,\n",
       " 0.029441386461257935,\n",
       " 0.0671597346663475,\n",
       " 0.0025576308835297823,\n",
       " 0.028602181002497673,\n",
       " -0.018605684861540794,\n",
       " 0.05013180524110794,\n",
       " -0.0542902871966362,\n",
       " -0.03664889186620712,\n",
       " 0.040750712156295776,\n",
       " -0.044509004801511765,\n",
       " -0.07576945424079895,\n",
       " 0.0016938719199970365,\n",
       " -0.04662192612886429,\n",
       " -0.02760942094027996,\n",
       " 0.0392257384955883,\n",
       " 0.010924643836915493,\n",
       " -0.0143031757324934,\n",
       " 0.048677846789360046,\n",
       " 0.01945548690855503,\n",
       " -0.0165046788752079,\n",
       " 0.05750593915581703,\n",
       " 0.017886588349938393,\n",
       " 0.016367116943001747,\n",
       " 0.006838107947260141,\n",
       " -0.0027852400671690702,\n",
       " -0.028113022446632385,\n",
       " 0.03293533995747566,\n",
       " -0.008162261918187141,\n",
       " 0.016503559425473213,\n",
       " -0.0008890617173165083,\n",
       " -0.011331772431731224,\n",
       " 0.01560590323060751,\n",
       " -0.002747876103967428,\n",
       " -0.023822380229830742,\n",
       " 0.008317090570926666,\n",
       " -0.033890966325998306,\n",
       " 0.011247474700212479,\n",
       " -0.02326224185526371,\n",
       " -0.014204729348421097,\n",
       " -0.031394872814416885,\n",
       " 0.006071117240935564,\n",
       " -0.03975209593772888,\n",
       " 0.006350292824208736,\n",
       " 0.03685023635625839,\n",
       " 0.011773370206356049,\n",
       " -0.043271128088235855,\n",
       " 0.022107595577836037,\n",
       " -0.03222227841615677,\n",
       " 0.004633280448615551,\n",
       " 0.01861286163330078,\n",
       " -0.0461781807243824,\n",
       " -0.013411097228527069,\n",
       " -0.014593689702451229,\n",
       " -0.017189396545290947,\n",
       " -0.037615299224853516,\n",
       " -0.01175762340426445,\n",
       " 0.029062220826745033,\n",
       " -0.017437946051359177,\n",
       " 0.0454525351524353,\n",
       " -0.05209745094180107,\n",
       " -0.029428549110889435,\n",
       " 0.03321756049990654,\n",
       " 0.02435440942645073,\n",
       " -0.0358048640191555,\n",
       " 0.022126683965325356,\n",
       " -0.00966416671872139,\n",
       " 0.08779031038284302,\n",
       " -0.03464784100651741,\n",
       " -0.043734170496463776,\n",
       " 0.05736429989337921,\n",
       " -0.014013061299920082,\n",
       " 0.006000404711812735,\n",
       " -0.02421995811164379,\n",
       " 0.016350895166397095,\n",
       " 0.044808026403188705,\n",
       " -0.025562455877661705,\n",
       " 0.07690118998289108,\n",
       " 0.010970678180456161,\n",
       " 0.04207293689250946,\n",
       " -0.022715603932738304,\n",
       " -0.04467586800456047,\n",
       " -0.003055560402572155,\n",
       " -0.023600663989782333,\n",
       " -0.013115497305989265,\n",
       " 0.04398322477936745,\n",
       " 0.023938285186886787,\n",
       " -0.011075073853135109,\n",
       " -0.03778417780995369,\n",
       " 0.00021477344853337854,\n",
       " -0.010648282244801521,\n",
       " -0.05003296211361885,\n",
       " 0.07658620178699493,\n",
       " 0.03315397724509239,\n",
       " -0.02210102789103985,\n",
       " 0.05767066404223442,\n",
       " 0.0006767681916244328,\n",
       " -0.003242972306907177,\n",
       " 0.020267846062779427,\n",
       " 0.0006321387481875718,\n",
       " 0.0009972446132451296,\n",
       " -0.02512633241713047,\n",
       " -0.03888467326760292,\n",
       " 0.04662318155169487,\n",
       " 0.023061562329530716,\n",
       " -0.04041805863380432,\n",
       " -0.038651108741760254,\n",
       " -0.027900371700525284,\n",
       " 0.024071509018540382,\n",
       " 0.05060867220163345,\n",
       " 0.05143703520298004,\n",
       " -0.002084001898765564,\n",
       " 0.0024474747478961945,\n",
       " 0.032136015594005585,\n",
       " 0.019393740221858025,\n",
       " -0.07943607866764069,\n",
       " 0.02427038736641407,\n",
       " -0.06520397216081619,\n",
       " 0.031165381893515587,\n",
       " -0.035928234457969666,\n",
       " 0.03409767523407936,\n",
       " 0.030861197039484978,\n",
       " 0.03538651764392853,\n",
       " 0.042785514146089554,\n",
       " -0.03435273468494415,\n",
       " -0.015017978847026825,\n",
       " -0.03510842099785805,\n",
       " 0.006179507356137037,\n",
       " -0.05111760273575783,\n",
       " 0.012249006889760494,\n",
       " 0.005350593011826277,\n",
       " 0.03790914639830589,\n",
       " -0.07914953678846359,\n",
       " 0.017817426472902298,\n",
       " 0.0395965501666069,\n",
       " 0.036239635199308395,\n",
       " 0.012556263245642185,\n",
       " -0.050666097551584244,\n",
       " 0.057882554829120636,\n",
       " 0.06475129723548889,\n",
       " -0.0725456178188324,\n",
       " 0.03519894927740097,\n",
       " 0.030570028349757195,\n",
       " -0.006167229264974594,\n",
       " -0.011796296574175358,\n",
       " -0.008290175348520279,\n",
       " -0.017933540046215057,\n",
       " -0.04209362342953682,\n",
       " -0.012064228765666485,\n",
       " 0.00880552176386118,\n",
       " -0.05999321490526199,\n",
       " -0.03464368358254433,\n",
       " -0.08186905086040497,\n",
       " 0.0355706512928009,\n",
       " -0.04216013848781586,\n",
       " -0.10391668230295181,\n",
       " 0.0038084639236330986,\n",
       " -0.030506454408168793,\n",
       " 0.0399044007062912,\n",
       " 0.03539436310529709,\n",
       " -0.01851348765194416,\n",
       " -0.030506830662488937,\n",
       " 0.01296560000628233,\n",
       " 0.02962312288582325,\n",
       " -0.05594923719763756,\n",
       " 0.026137271896004677,\n",
       " 0.027979889884591103,\n",
       " -0.032783620059490204,\n",
       " -0.05861344188451767,\n",
       " 0.029305243864655495,\n",
       " 0.025631634518504143,\n",
       " 0.046621762216091156,\n",
       " -0.01578911766409874,\n",
       " -0.05855393409729004,\n",
       " -0.033567510545253754,\n",
       " -0.022099914029240608,\n",
       " 0.07099347561597824,\n",
       " -0.015482406131923199,\n",
       " -0.02221505530178547,\n",
       " 0.020550455898046494,\n",
       " 0.03193112462759018,\n",
       " 0.009649628773331642,\n",
       " 0.08112385869026184,\n",
       " 0.024486811831593513,\n",
       " -0.020967384800314903,\n",
       " -0.001703555346466601,\n",
       " 0.003984694369137287,\n",
       " 0.01214590948075056,\n",
       " 0.02251713164150715,\n",
       " 0.011797886341810226,\n",
       " -0.014598767273128033,\n",
       " -0.027774184942245483,\n",
       " 0.035769712179899216,\n",
       " -0.04636594280600548,\n",
       " 0.006575292441993952,\n",
       " 0.01091056503355503,\n",
       " 0.06001884862780571,\n",
       " -0.03792550787329674,\n",
       " 0.025552064180374146,\n",
       " -0.052944615483284,\n",
       " -0.00331985205411911,\n",
       " 0.04723644629120827,\n",
       " 0.04916655644774437,\n",
       " -0.012118092738091946,\n",
       " -0.015976974740624428,\n",
       " -0.023780548945069313,\n",
       " -0.020015906542539597,\n",
       " -0.016765648499131203,\n",
       " 0.017619017511606216,\n",
       " 0.09507094323635101,\n",
       " 0.02456720732152462,\n",
       " -0.00030371572938747704,\n",
       " 0.07726727426052094,\n",
       " 0.009286770597100258,\n",
       " 0.04579121246933937,\n",
       " 0.0006386045133695006,\n",
       " -0.0203663669526577,\n",
       " 0.05929982289671898,\n",
       " -0.009882405400276184,\n",
       " 0.017564021050930023,\n",
       " -0.05515163019299507,\n",
       " 0.016189292073249817,\n",
       " 0.028766026720404625,\n",
       " -0.03514404594898224,\n",
       " -0.04935841262340546,\n",
       " -0.02447367087006569,\n",
       " -0.02685004286468029,\n",
       " -0.009837007150053978,\n",
       " 9.710079029900953e-05,\n",
       " 0.019255781546235085,\n",
       " 0.016495689749717712,\n",
       " 0.019392136484384537,\n",
       " 0.014026164077222347,\n",
       " 0.044185783714056015,\n",
       " -0.0408172607421875,\n",
       " 0.058831170201301575,\n",
       " 0.033452264964580536,\n",
       " -0.07100701332092285,\n",
       " -0.01207928266376257,\n",
       " 0.017947617918252945,\n",
       " 0.026635218411684036,\n",
       " -0.042489077895879745,\n",
       " -0.025743063539266586,\n",
       " 0.04628248140215874,\n",
       " 0.02357054501771927,\n",
       " 0.012330091558396816,\n",
       " -0.019114600494503975,\n",
       " 0.04284172132611275,\n",
       " 0.020867055281996727,\n",
       " -0.020985012874007225,\n",
       " 0.049807094037532806,\n",
       " -0.06530244648456573,\n",
       " 0.06784137338399887,\n",
       " 0.06132720038294792,\n",
       " -0.025619087740778923,\n",
       " -0.01975896954536438,\n",
       " -0.028557993471622467,\n",
       " -0.0033664510119706392,\n",
       " -0.022265056148171425,\n",
       " 0.0277670007199049,\n",
       " 0.0376681424677372,\n",
       " -0.01844070851802826,\n",
       " -0.0666554793715477,\n",
       " -0.03576522693037987,\n",
       " -0.006980367470532656,\n",
       " -0.009456862695515156,\n",
       " 0.007616228424012661,\n",
       " -0.002117250580340624,\n",
       " -0.000508638215251267,\n",
       " -0.058485377579927444,\n",
       " 0.02196097932755947,\n",
       " 0.011461308225989342,\n",
       " -0.019124537706375122,\n",
       " 0.017011091113090515,\n",
       " -0.03894034028053284,\n",
       " -0.024677084758877754,\n",
       " -0.009032917208969593,\n",
       " 0.019948668777942657,\n",
       " -0.020086267963051796,\n",
       " 0.0046862466260790825,\n",
       " 0.0658910721540451,\n",
       " -0.021722840145230293,\n",
       " -0.0028560664504766464,\n",
       " 0.011400393210351467,\n",
       " -0.014010073617100716,\n",
       " -0.05337538197636604,\n",
       " -0.07439275830984116,\n",
       " 0.0002861053217202425,\n",
       " 0.04116436839103699,\n",
       " 0.03818747028708458,\n",
       " -0.012812647968530655,\n",
       " 0.05230933055281639,\n",
       " 0.018940966576337814,\n",
       " -0.048808012157678604,\n",
       " -0.06779120117425919,\n",
       " -0.01911095529794693,\n",
       " -0.028975164517760277,\n",
       " 0.004133264068514109,\n",
       " 0.01923450082540512,\n",
       " -0.020669246092438698,\n",
       " -0.003695683553814888,\n",
       " 0.009470553137362003,\n",
       " -0.041596852242946625,\n",
       " 0.045980364084243774,\n",
       " 0.029285280033946037,\n",
       " -0.07706877589225769,\n",
       " 0.006656208075582981,\n",
       " -0.005012008361518383,\n",
       " -0.017416084185242653,\n",
       " 0.007063459139317274,\n",
       " -0.05976015701889992,\n",
       " 0.0185412485152483,\n",
       " -0.0273988489061594,\n",
       " 0.005803277250379324,\n",
       " -0.041785452514886856,\n",
       " -0.0908936932682991,\n",
       " -0.006833197548985481,\n",
       " -0.014357824809849262,\n",
       " 0.08537802845239639,\n",
       " -0.05669703334569931,\n",
       " 0.06276111304759979,\n",
       " 0.0009012018563225865,\n",
       " -0.007769424468278885,\n",
       " -0.02144297957420349,\n",
       " -0.11318439245223999,\n",
       " 0.07541830092668533,\n",
       " 0.023151574656367302,\n",
       " 0.005866213236004114,\n",
       " -0.004821085371077061,\n",
       " -0.010738340206444263,\n",
       " 0.02703235298395157,\n",
       " 0.025599531829357147,\n",
       " 0.007024332880973816,\n",
       " -0.032584112137556076,\n",
       " -0.04185543581843376,\n",
       " -0.024687552824616432,\n",
       " -0.02051878534257412,\n",
       " -0.04894666746258736,\n",
       " 0.03619479760527611,\n",
       " -0.04281015321612358,\n",
       " 0.014844655990600586,\n",
       " 0.010251615196466446,\n",
       " 0.023320626467466354,\n",
       " 0.01871577650308609,\n",
       " 0.03378577157855034,\n",
       " -0.025527965277433395,\n",
       " 0.044417854398489,\n",
       " -0.02600604109466076,\n",
       " -0.0119530213996768,\n",
       " -0.055049628019332886,\n",
       " 0.022267477586865425,\n",
       " -0.010707407258450985,\n",
       " -0.026371469721198082,\n",
       " -0.009768350049853325,\n",
       " -0.01535708550363779,\n",
       " -0.019579773768782616,\n",
       " -0.021421188488602638,\n",
       " 0.006235864479094744,\n",
       " 0.0314040407538414,\n",
       " 0.031010085716843605,\n",
       " 0.004555661231279373,\n",
       " -0.031087100505828857,\n",
       " -0.014605932869017124,\n",
       " -0.003368874778971076,\n",
       " -0.028359955176711082,\n",
       " 0.057969674468040466,\n",
       " -0.09270115196704865,\n",
       " -0.009005305357277393,\n",
       " 0.022297324612736702,\n",
       " -0.02122938074171543,\n",
       " -0.03563996031880379,\n",
       " 0.004106925334781408,\n",
       " 0.006597382482141256,\n",
       " 0.03264277055859566,\n",
       " 0.03904365748167038,\n",
       " 0.02032073214650154,\n",
       " 0.005939505994319916,\n",
       " 0.010560653172433376,\n",
       " -0.002243859926238656,\n",
       " 0.02130184881389141,\n",
       " -0.02763022854924202,\n",
       " 0.014897515065968037,\n",
       " -0.020667249336838722,\n",
       " -0.09472247958183289,\n",
       " -0.0004307603812776506,\n",
       " -0.02479407750070095,\n",
       " 0.028932971879839897,\n",
       " 0.025980545207858086,\n",
       " 0.057643499225378036,\n",
       " -0.0374685563147068,\n",
       " 0.0006257054628804326,\n",
       " -0.01778700202703476,\n",
       " 0.017848286777734756,\n",
       " -0.00700916163623333,\n",
       " -0.026394061744213104,\n",
       " 0.03204090893268585,\n",
       " -0.005773015785962343,\n",
       " -0.012837935239076614,\n",
       " 0.016041608527302742,\n",
       " 0.030365966260433197,\n",
       " -0.025132445618510246,\n",
       " 0.0380871519446373,\n",
       " 0.026565272361040115,\n",
       " 0.061460208147764206,\n",
       " 0.018262824043631554,\n",
       " -0.025590986013412476,\n",
       " -0.014801396057009697,\n",
       " -0.009373162873089314,\n",
       " -0.05065552145242691,\n",
       " -0.01938270404934883,\n",
       " 0.04338742420077324,\n",
       " -0.008704069070518017,\n",
       " 0.020551657304167747,\n",
       " 0.010078946128487587,\n",
       " -0.022332625463604927,\n",
       " 0.013624574989080429,\n",
       " -0.029078511521220207,\n",
       " -0.02031247317790985,\n",
       " 0.04527844116091728,\n",
       " 0.008548842743039131,\n",
       " -0.044655926525592804,\n",
       " -0.04993825778365135,\n",
       " -0.0005616651615127921,\n",
       " -0.0019093779847025871,\n",
       " 0.029475873336195946,\n",
       " 0.08492345362901688,\n",
       " 0.02737259492278099,\n",
       " -0.019202347844839096,\n",
       " -0.011180019937455654,\n",
       " 0.0613800473511219,\n",
       " 0.0009942551841959357,\n",
       " -0.005685679614543915,\n",
       " 0.010302840732038021,\n",
       " 0.0048909238539636135,\n",
       " 0.03689644858241081,\n",
       " 6.452776142396033e-05,\n",
       " -0.02497044950723648,\n",
       " 0.006457015406340361,\n",
       " -0.03664189949631691,\n",
       " -0.03386320546269417,\n",
       " -0.009320611134171486,\n",
       " 0.027527937665581703,\n",
       " -0.006957217585295439,\n",
       " -0.0016937933396548033,\n",
       " 0.02136092633008957,\n",
       " 0.008775141090154648,\n",
       " 0.031389400362968445,\n",
       " 0.05911479890346527,\n",
       " 0.10196645557880402,\n",
       " 0.03833167254924774,\n",
       " 0.059265561401844025,\n",
       " -0.034477267414331436,\n",
       " 0.01983230747282505,\n",
       " -0.028979182243347168,\n",
       " -0.0006717467331327498,\n",
       " 0.023720132187008858,\n",
       " 0.009949897415935993,\n",
       " -0.027036644518375397,\n",
       " -0.02788533642888069,\n",
       " -0.009638091549277306,\n",
       " -0.017497442662715912,\n",
       " 0.05965723469853401,\n",
       " -0.023421915248036385,\n",
       " -7.17904549674131e-05,\n",
       " -0.023910334333777428,\n",
       " 0.010167197324335575,\n",
       " 0.06294538080692291,\n",
       " -0.007855839096009731,\n",
       " 0.009582506492733955,\n",
       " -0.00771779241040349,\n",
       " 0.010753695853054523,\n",
       " 0.029988912865519524,\n",
       " -0.0410747155547142,\n",
       " 0.014009366743266582,\n",
       " -0.016409873962402344,\n",
       " -0.025754181668162346,\n",
       " -0.029275324195623398,\n",
       " 0.06891670823097229,\n",
       " 0.00874270685017109,\n",
       " 0.023196490481495857,\n",
       " -0.038228556513786316,\n",
       " 0.016259821131825447,\n",
       " -0.013566256500780582,\n",
       " 0.025782182812690735,\n",
       " -0.020683975890278816,\n",
       " 0.04356987029314041,\n",
       " 0.03843095898628235,\n",
       " 0.011759771965444088,\n",
       " 0.0006424587918445468,\n",
       " 0.06934863328933716,\n",
       " 0.004451766610145569,\n",
       " 0.05257083848118782,\n",
       " 0.05299004167318344,\n",
       " -0.027428876608610153,\n",
       " 0.007362625561654568,\n",
       " -0.027196450158953667,\n",
       " -0.03716901317238808,\n",
       " -0.05996355041861534,\n",
       " -0.018047159537672997,\n",
       " 0.010596984066069126,\n",
       " -0.019895626232028008,\n",
       " -0.02837696112692356,\n",
       " -0.02666792832314968,\n",
       " 0.005059539806097746,\n",
       " -0.00711184972897172,\n",
       " 0.028563370928168297,\n",
       " 0.10317031294107437,\n",
       " 0.04524599015712738,\n",
       " -0.09671919792890549,\n",
       " -0.05298631638288498,\n",
       " -0.02709105610847473,\n",
       " -0.03117411397397518,\n",
       " -0.010037784464657307,\n",
       " 0.0028370970394462347,\n",
       " -0.01989951729774475,\n",
       " 0.054531022906303406,\n",
       " 0.017425885424017906,\n",
       " -0.031392212957143784,\n",
       " -0.0492844320833683,\n",
       " 0.012391205877065659,\n",
       " 0.021212412044405937,\n",
       " -0.010904794558882713,\n",
       " -0.02079067938029766,\n",
       " 0.010785725899040699,\n",
       " 0.0042291851714253426,\n",
       " 0.007526397705078125,\n",
       " 0.018077723681926727,\n",
       " -0.030186735093593597,\n",
       " -0.06504229456186295,\n",
       " -0.0060129123739898205,\n",
       " 0.04470229893922806,\n",
       " -0.0001683917362242937,\n",
       " 0.014180039055645466,\n",
       " 0.02072112262248993,\n",
       " 0.001374627579934895,\n",
       " 0.03986472263932228,\n",
       " 0.02338232658803463,\n",
       " 0.0028986725956201553,\n",
       " 0.018854621797800064,\n",
       " 0.018174119293689728,\n",
       " 0.008018970489501953,\n",
       " -0.001832504291087389,\n",
       " 0.004592920653522015,\n",
       " -0.01788954995572567,\n",
       " 0.004617960192263126,\n",
       " -0.028025709092617035,\n",
       " 0.04705401882529259,\n",
       " 0.027661263942718506,\n",
       " 0.0065150074660778046,\n",
       " -0.030028309673070908,\n",
       " -0.05390259250998497,\n",
       " -0.0013852387201040983,\n",
       " -0.01643216609954834,\n",
       " -0.06801334023475647,\n",
       " 0.05069683864712715,\n",
       " 0.06540688872337341,\n",
       " 0.01848502829670906,\n",
       " 0.03506237268447876,\n",
       " 0.015128708444535732,\n",
       " -0.0009853191440925002,\n",
       " 0.018667006865143776,\n",
       " -0.02371547929942608,\n",
       " -0.03277934715151787,\n",
       " -0.04126175865530968,\n",
       " 0.0004407509695738554,\n",
       " -0.006913974415510893,\n",
       " 0.001071878825314343,\n",
       " 0.04121888801455498,\n",
       " 0.033742137253284454,\n",
       " 0.06251147389411926,\n",
       " 0.07336639612913132,\n",
       " 0.036337900906801224,\n",
       " -0.020660797134041786,\n",
       " -0.023938000202178955,\n",
       " 0.02654903009533882,\n",
       " -0.009692799299955368,\n",
       " -0.04504105821251869,\n",
       " 0.022294068709015846,\n",
       " 0.03183344379067421,\n",
       " -0.013615928590297699,\n",
       " 0.09686916321516037,\n",
       " 0.05850844457745552,\n",
       " 0.05051637440919876,\n",
       " 0.06556273996829987,\n",
       " -0.030124453827738762,\n",
       " -0.05741645395755768,\n",
       " 0.08546410501003265,\n",
       " -0.09430325776338577,\n",
       " -0.0328102707862854,\n",
       " -0.026789216324687004,\n",
       " 0.03717803210020065,\n",
       " 0.08715295791625977,\n",
       " 0.0001604699791641906,\n",
       " -0.009505724534392357,\n",
       " -0.01792062073945999,\n",
       " 0.008379129692912102,\n",
       " 0.0796549916267395,\n",
       " 0.033412281423807144,\n",
       " 0.04523250833153725,\n",
       " 0.002415842143818736,\n",
       " -0.08875352889299393,\n",
       " -0.02112312614917755,\n",
       " 0.034831877797842026,\n",
       " 0.008336428552865982,\n",
       " 0.03964807465672493,\n",
       " 0.022455615922808647,\n",
       " 0.010564827360212803,\n",
       " -0.02183358184993267,\n",
       " -0.03671906143426895,\n",
       " 0.016374699771404266,\n",
       " -0.07664699852466583,\n",
       " -0.04381590336561203,\n",
       " 0.008805062621831894,\n",
       " -0.029425987973809242,\n",
       " 0.035350218415260315,\n",
       " 0.03271523490548134,\n",
       " -0.008388573303818703,\n",
       " -0.021349893882870674,\n",
       " 0.01584000512957573,\n",
       " -0.014425228349864483,\n",
       " -0.001280902768485248,\n",
       " -0.015345528721809387,\n",
       " -0.05014083534479141,\n",
       " 0.004639973398298025,\n",
       " 0.00799761712551117,\n",
       " 0.01279925275593996,\n",
       " 0.01869218423962593,\n",
       " 0.050975508987903595,\n",
       " -0.004513971973210573]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.embed_query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Data injestion into vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6d22ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92fddc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d3f762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path=os.path.join(os.getcwd(), \"data\", \"sample.pdf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1f9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(file_path)\n",
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575ed93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can take the entire document(77 pages) or split it into smaller chunks.\n",
    "#small chunks are better for vector DBs and helps in preserving the context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9085eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a experimental value, there is no one size fits all. Hyperparameter tuning is required.\n",
    "# study various chunking state-of-the-art techniques.\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, \n",
    "    chunk_overlap=200, \n",
    "    length_function=len\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7278b737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=text_splitter.split_documents(documents)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3207d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvronâˆ— Louis Martinâ€  Kevin Stoneâ€ \\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0e8fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectorstore =  FAISS.from_documents(\n",
    "    docs,embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. in-memory --> (FAISS, Chroma, etc.)\n",
    "#2. on-disc (FAISS, Chroma, etc.)\n",
    "#3. cloud storage (pinecone, weaviate, milvus, mongodbvectorsearch, astradb etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93fa6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_document = vectorstore.similarity_search(\"what is the llama 2 llm model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b06a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is retrieval process from vector DB.\n",
    "relevant_document[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "001d424b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_document[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eb78d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English, and has not covered, nor could it cover all scenarios. For these reasons, as with all LLMs,\\nLlama 2â€™s potential outputs cannot be predicted in advance, and the model may in some instances\\nproduce inaccurate or objectionable responses to user prompts. Therefore, before deploying any\\napplications ofLlama 2, developers should perform safety testing and tuning tailored to their\\nspecific applications of the model. Please see the Responsible Use Guide available available at'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_document[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c1743fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'more recent, up to July 2023.\\nEvaluation Results\\nSee evaluations for pretraining (Section 2); fine-tuning (Section 3); and safety (Section 4).\\nEthical Considerations and Limitations(Section 5.2)\\nLlama 2is a new technology that carries risks with use. Testing conducted to date has been in\\nEnglish, and has not covered, nor could it cover all scenarios. For these reasons, as with all LLMs,\\nLlama 2â€™s potential outputs cannot be predicted in advance, and the model may in some instances'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_document[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ea8960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6ab877c7-51d1-4319-88a7-6df2c35828e1', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='Llama 1\\n7B 76.5 79.8 48.9 76.1 70.1 72.8 47.6 57.2 33.6 35.1\\n13B 78.1 80.1 50.4 79.2 73.0 74.8 52.7 56.4 62.0 46.9\\n33B 83.1 82.3 50.4 82.8 76.0 80.0 57.8 58.6 72.5 57.8\\n65B 85.3 82.8 52.3 84.2 77.0 78.9 56.0 60.2 74.0 63.4\\nLlama 2\\n7B 77.4 78.8 48.3 77.2 69.2 75.2 45.9 58.6 57.8 45.3\\n13B 81.7 80.5 50.3 80.7 72.8 77.3 49.4 57.0 67.3 54.8\\n34B 83.7 81.9 50.9 83.3 76.7 79.4 54.5 58.2 74.3 62.6\\n70B 85.0 82.8 50.7 85.3 80.2 80.2 57.4 60.2 78.5 68.9\\nTable 20: Performance on standard benchmarks.'),\n",
       " Document(id='d57c6762-01a7-4d4b-9ac3-98b8e7e8f981', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='Llama 1\\n7B 14.1 60.8 46.2 58.5 6.95 35.1 30.3 23.9\\n13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='86eec6b6-9eaa-4d2c-9326-16c644478ead', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='711be74a-0cec-4ad2-aa9d-57fc07007c46', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='d17b30c7-7208-4869-bff1-0d698f18a600', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 4, 'page_label': '5'}, page_content='final learning rate down to 10% of the peak learning rate. We use a weight decay of0.1 and gradient clipping\\nof 1.0. Figure 5 (a) shows the training loss forLlama 2with these hyperparameters.\\n5'),\n",
       " Document(id='b04a7474-6be9-41b0-9735-abccc090ae0e', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 76, 'page_label': '77'}, page_content='Out-of-Scope UsesUse in any manner that violates applicable laws or regulations (including trade\\ncompliance laws). Use in languages other than English. Use in any other way\\nthat is prohibited by the Acceptable Use Policy and Licensing Agreement for\\nLlama 2.\\nHardware and Software(Section 2.2)\\nTraining Factors We used custom training libraries, Metaâ€™s Research Super Cluster, and produc-\\ntion clusters for pretraining. Fine-tuning, annotation, and evaluation were also'),\n",
       " Document(id='4efbac35-d18a-46c1-a641-159c1c61ac41', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 72, 'page_label': '73'}, page_content='65B 0.37 0.27 0.20 0.30 0.19\\nLlama 2\\n7B 0.34 0.28 0.30 0.24 0.16\\n13B 0.29 0.33 0.35 0.33 0.19\\n34B 0.31 0.24 0.32 0.34 0.28\\n70B 0.42 0.29 0.34 0.37 0.20\\nFine-tuned\\nChatGPT 0.19 0.16 0.21 0.17 0.17\\nMPT-instruct 7B 0.35 0.29 0.33 0.41 0.14\\nFalcon-instruct 7B 0.34 0.26 0.30 0.33 0.29\\nLlama 2-Chat\\n7B 0.55 0.50 0.48 0.45 0.62\\n13B 0.40 0.50 0.71 0.40 0.62\\n34B 0.44 0.54 0.63 0.53 0.53\\n70B 0.47 0.52 0.50 0.55 0.50'),\n",
       " Document(id='b52b902b-698c-45c4-a9bd-33e5cf02d325', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 37, 'page_label': '38'}, page_content='DaveCummings,MatthiasPlappert,FotiosChantzis,ElizabethBarnes,ArielHerbert-Voss,WilliamHebgen\\nGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,\\nWilliam Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan\\nMorikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder,\\nBob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large'),\n",
       " Document(id='f2a38c80-2de9-41c9-baf3-e9200ae091fd', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 37, 'page_label': '38'}, page_content='ProcessingSystems,volume33,pages1877â€“1901.CurranAssociates,Inc.,2020. URL https://proceedings.\\nneurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\\nMark Chen, Jerry Tworek, HeewooJun, Qiming Yuan, HenriquePonde deOliveira Pinto, JaredKaplan, Harri\\nEdwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael\\nPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,'),\n",
       " Document(id='89fe1554-317c-4e4c-9413-8862e6f3f038', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'd:\\\\LLMOPS\\\\DOCUMENT_PORTAL\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='7B 10.5 36.5 17.7 56.2\\n13B 15.8 52.5 22.0 64.0\\n33B 21.7 70.7 30.2 73.4\\n65B 23.7 79.3 37.7 76.8\\nLlama 2\\n7B 12.8 45.6 20.8 62.8\\n13B 18.3 60.2 30.6 69.0\\n34B 22.6 77.2 33.0 76.1\\n70B 29.9 89.0 45.0 81.4\\nTable 21: Code generation results on Human-Eval and MBPP. We report 0-shot and 3-shot results for\\nHuman-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top-p=0.95.\\n49')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10}) #can be used to create a retriever chain.\n",
    "\n",
    "retriever.invoke(\"llama2 finetuning benchmark experiments.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba7eb11",
   "metadata": {},
   "source": [
    "# Question: user question\n",
    "# Context: based on the question retrieving the info from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ae1e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provided below. \n",
    "        If the context does not contain sufficient information, respond with: \n",
    "        \"I do not have enough information about this.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80737050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1939fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e849ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this prompt will go to the LLM model for inference.\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f399a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c615c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77432d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "135e53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "789e3c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study LCEL concept\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f134e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let\\'s try to figure out the answer to the question about the Llama 2 fine-tuning benchmark experiments based on the provided context. First, I need to understand what the user is asking. They want information about the fine-tuning experiments related to Llama 2. \\n\\nLooking at the context, there are several tables mentioned. The main sections are Table 20, Table 3, and some other data points. The user is specifically interested in the fine-tuning benchmarks. \\n\\nIn the context, there\\'s a mention of \"Fine-tuned\" models in the tables. For example, under the \"Fine-tuned\" section, there are entries like \"ChatGPT\", \"MPT-instruct 7B\", \"Falcon-instruct 7B\", and \"Llama 2-Chat\" with different parameters (7B, 13B, 34B, 70B). These numbers likely correspond to the model sizes. \\n\\nThe tables have numerical data, but the exact meaning isn\\'t clear from the context. However, some sections mention performance metrics. For example, in Table 21, there are code generation results on Human-Eval and MBPP with pass@1 and pass@100 scores. These metrics are common in machine learning benchmarks for evaluating model performance on coding tasks.\\n\\nAdditionally, the context mentions hyperparameters like the final learning rate being reduced to 10% of the peak, weight decay of 0.1, and gradient clipping of 1.0 used during training. These are typical parameters in training and fine-tuning processes. \\n\\nThe user\\'s question is about the fine-tuning benchmark experiments. The answer should include details on how Llama 2 models were fine-tuned, the benchmarks used, and the results. From the context, there\\'s a part that says \"We use a weight decay of 0.1 and gradient clipping of 1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\" This indicates that the fine-tuning process involved specific hyperparameters and training loss was monitored.\\n\\nLooking at the tables with \"Fine-tuned\" data, the numbers might represent performance scores on various benchmarks. For example, the Llama 2-Chat models (7B, 13B, etc.) have different scores compared to other models like ChatGPT or MPT-instruct. However, without the exact benchmark names, it\\'s a bit challenging, but the tables are labeled as \"Overall performance on grouped academic benchmarks\" and \"Code generation results\".\\n\\nThe context also mentions that in Table 3, the performance is grouped into categories and that individual benchmarks are in Section A.2.2, but that section isn\\'t provided here. The user might be looking for a summary of these results. \\n\\nIn the code generation results (Table 21), Llama 2 models show improvements over Llama 1, especially in larger models like 70B. For instance, Llama 2 70B has a pass@1 score of 29.9 on Human-Eval, which is higher than Llama 1\\'s 23.7. This suggests that the fine-tuning experiments led to better performance on coding tasks.\\n\\nMoreover, under the \"Fine-tuned\" section, there are numerical values for different models. For example, Llama 2 70B has 0.47, 0.52, 0.50, 0.55, 0.50 in some benchmarks compared to others. However, without knowing the exact benchmarks, it\\'s hard to specify, but these numbers likely represent performance metrics like accuracy or F1 scores.\\n\\nThe context also mentions that the results are compared to open-source base models and that safety benchmarks are in a different section. This implies that the fine-tuning experiments evaluated Llama 2 against other models and different versions (like Llama 1) across multiple benchmarks.\\n\\nIn summary, the answer should highlight that Llama 2\\'s fine-tuning involved specific hyperparameters, training on various clusters, and resulted in improved performance on benchmarks compared to previous versions and other models. The tables show that larger models (like 70B) outperformed smaller ones, and the code generation results improved significantly.\\n</think>\\n\\nThe Llama 2 fine-tuning benchmark experiments involved evaluating model performance across various academic and code-generation benchmarks. Key details include:\\n\\n1. **Hyperparameters**: Training used a final learning rate reduced to 10% of the peak, weight decay of 0.1, and gradient clipping of 1.0. These settings were applied during pretraining and fine-tuning phases.\\n\\n2. **Results on Academic Benchmarks**:\\n   - Llama 2 models (7B, 13B, 34B, 70B) showed improvements over Llama 1 and other open-source models in grouped academic benchmarks (Table 3). For example, the 70B variant achieved **85.0%** in one metric, outperforming Llama 1â€™s 65B version (85.3% vs. 83.1%).\\n   - Fine-tuned variants like **Llama 2-Chat** (7B, 13B, 34B, 70B) demonstrated strong performance in specific benchmarks, with the 70B model achieving **0.55** in one category, outperforming models like ChatGPT and Falcon-instruct.\\n\\n3. **Code Generation Performance** (Table 21):\\n   - Llama 2 models excelled in code generation tasks on Human-Eval and MBPP. For instance, the 70B model achieved **29.9% pass@1** on Human-Eval and **89.0% pass@100**, surpassing Llama 1â€™s 65B model (23.7% and 79.3%, respectively).\\n\\n4. **Comparisons**:\\n   - Llama 2â€™s 70B variant outperformed competitors like Falcon-instruct and MPT-instruct in most benchmarks, with notable gains in larger models (e.g., **45.0% pass@1** on MBPP for Llama 2 70B vs. 37.7% for Llama 1 65B).\\n\\nThese experiments highlight Llama 2â€™s enhanced capabilities through fine-tuning, particularly in larger model sizes and specialized tasks like code generation.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell  me about the llama2 finetuning benchmark experiments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94360586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, let\\'s tackle this question about scaling trends for the reward model. The user wants to know what the scaling trends are, so I need to find relevant information in the provided context.\\n\\nFirst, I\\'ll scan through the context to find mentions of scaling. The first paragraph mentions \"Scaling Trends. We study the scaling trends in terms of data and model size for the reward model, fine-tuning different model sizes on an increasing amount of the reward model data collected each week...\" So that\\'s a key point. They looked at how model size and data volume affect performance.\\n\\nThe next part says \"Figure6reportsthesetrends,showingtheexpectedresultthatlarger models obtain higher performance for a similar volume of data.\" So larger models perform better with the same data amount. Also, \"More importantly, the scaling performance in ranking loss.\" Hmm, maybe the ranking loss improves with scaling?\\n\\nThen there\\'s mention of a margin term leading to a binary split in reward distribution, especially with larger margins. The reward model does better on separable pairs but worse on similar ones when the margin is larger. But how does this relate to scaling trends? Maybe the scaling trends also involve how model size interacts with the margin parameter.\\n\\nThe context also talks about experiments with different model versions (like RLHF-v5, SFT-v2, etc.), but those might be more about specific configurations rather than scaling trends generally. The part about using human evaluations to validate models shows that they checked calibration against human preferences, which is important for the reward model\\'s effectiveness.\\n\\nPutting it all together: the main scaling trends are that larger models achieve higher performance with the same data volume. Also, the scaling performance relates to ranking loss, where larger models might handle ranking better. The margin term affects the distribution of rewards, causing a split between separable and similar pairs. However, the exact scaling of model size versus data size isn\\'t detailed beyond the initial statement. The answer should focus on the key points from the first paragraph and the results from Figure 6 mentioned.\\n</think>\\n\\nThe scaling trends for the reward model indicate that larger models achieve higher performance when trained on a similar volume of data. This is highlighted in the context, which states that \"larger models obtain higher performance for a similar volume of data.\" Additionally, the study observed scaling performance in ranking loss, though specific details on how model size interacts with ranking loss are not elaborated. The context also notes that increasing the margin term in the loss function leads to a binary split in reward distribution, improving performance on separable pairs but reducing effectiveness on similar samples. Overall, the key takeaway is that model size positively impacts performance, but trade-offs exist with margin-based training objectives.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"can you tell me Scaling trends for the reward model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "45a51790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user is asking for the largest country in Asia. Let me check the context provided.\\n\\nLooking at the context, under the \"Race and Ethnicity\" section, there are mentions of Indian, Chinese, Korean, Mexican, and Indigenous. The percentages are 16.5% for Indian and 16.3% for Chinese. But wait, the question is about the largest country in Asia by area, not population. The context here seems to be talking about demographic descriptors in documents, not geographical facts. The terms like \"Indian\" and \"Chinese\" here refer to nationality or ethnicity mentions in the data, not the countries themselves. \\n\\nThe user\\'s question is a straightforward geography question. The context provided doesn\\'t actually discuss the population or area of countries in Asia. It\\'s analyzing how often certain demographic terms are mentioned in documents. For example, \"Indian\" is mentioned 16.5% of the time, but that\\'s about references in texts, not the population size of India. So the context doesn\\'t provide the necessary information to answer which country is the largest by area or population. \\n\\nI need to make sure I\\'m not confusing the context\\'s data with the actual question. The context\\'s data on \"Indian\" and \"Chinese\" refers to mentions in documents, not the actual country sizes. Therefore, the correct answer should be that the context doesn\\'t have enough info. But the user is asking for the largest country in Asia, which is a general knowledge question. Since the context isn\\'t providing that data, I should respond that I don\\'t have enough information based on the provided context.\\n</think>\\n\\nI do not have enough information about this.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"the largest country in ASIA?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb3819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56289a3f",
   "metadata": {},
   "source": [
    "# One Small task\n",
    "Take 10 pdfs keep it in same directory and create RAG on top of it.\n",
    "\n",
    "26th July:\n",
    "\n",
    "\n",
    "In next class will discuss about the(will start with the modular coding)\n",
    "\n",
    "exception module\n",
    "\n",
    "logger module\n",
    "\n",
    "doc analyser\n",
    "\n",
    "doc compare\n",
    "\n",
    "utils and config\n",
    "\n",
    "2 class\n",
    "\n",
    "2 more class api and other module\n",
    "\n",
    "2 more class for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c70c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d29ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
